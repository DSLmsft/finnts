---
title: "Back Testing and Hyperparameter Tuning"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{back-testing-and-hyperparameter-tuning}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Default Hyperparameter Tuning

Most models in automatically included in finnts, including all multivariate models, have various hyperparameters with values that need to be chosen before a model is trained. finnts solves this by leveraging the [tune](https://tune.tidymodels.org/reference/tune.html) package within the tidymodels ecosystem. 

For each model that contains hyperparameters that need to be chosen before training,the entire historical data set is used to create various time series cross-validation splits using the [timetk](https://business-science.github.io/timetk/reference/time_series_cv.html) package. Refer to the code below for an example. 

```{r, message = FALSE, fig.width = 7, fig.height = 6}
library(dplyr)
library(modeltime)
library(timetk)

# monthly data example
timetk::time_series_cv(
    data = modeltime::m750 %>% dplyr::filter(date > "2010-12-01"), # entire historical data set
    initial = 24, # initial periods to use as training data
    assess = 6, # forecast horizon to hold out as testing data
    skip = 6, # how many periods to move forward for each subsequent split, 
              # equal to back_test_spacing input in forecast_time_series() finnts function
    cumulative = TRUE, # should the testing data expand in each subsequent split
    slice_limit = 3 # max number of splits to run
    ) %>%
  timetk::plot_time_series_cv_plan(.date_var = date, 
                                   .value = value, 
                                   # Additional arguments passed to plot_time_series(),
                                   .facet_ncol = 1,
                                   .interactive = FALSE)


```

A tuning grid is then created within the model, using the [tune_grid](https://tune.tidymodels.org/reference/tune_grid.html) function from tune, depending on the hyperparameters that were passed to tune when creating a model specification. The tuning grid also takes the time series cross-validation (tscv) splits that were created (see example above). So within each tscv split, every combination of hyperparameters are used to train a model then create a forecast to compare to the hold out testing data. The optimal combination of hyperparameters are chosen based on what had the lowest root mean squared error (RMSE) across all tscv slices. That optimal combination is then refitting on the entire historical data set and a fitted model is returned. 

## Model Refitting

Once every model is fitted on the entire historical data, with the final hyperarameters, it is then refitted again for back testing and to create the final future forecast. A time series cross validation process is ran again, similar to the process described in the hyperparameter selection process but with a few changes. 

First, The tscv process tries to go back as far as possible, where the "initial" argument in the time_series_cv() function is set to one year. That gives us enough historical forecasts to be leveraged in an ensemble model, in which a multivariate machine learning model is fed forecasts from separate models and tries to find the optimal combination of all of them. If these ensemble models are chosen by the user to not run in finnts, then the slice limit is equal to the back test scenario number calculated automatically by finnts or supplied by the user (with an additional run to create the future forecast). 

**Important Note:** test test 

